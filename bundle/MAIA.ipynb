{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865749bb217bdd8b",
   "metadata": {},
   "source": [
    "# MAIA\n",
    "\n",
    "This tutorial has the purpose to showcase all the major applications and functionalities available in MAIA. In detail, we will cover all the essential Medical AI lifecycle stages, to provide a comprehensive overview of the platform.\n",
    "\n",
    "The tutorial is based on two different datasets:\n",
    "- [**Decathlon Spleen**](http://medicaldecathlon.com/): a dataset of 3D spleen CT scans from the Medical Segmentation Decathlon challenge. This NIFTI dataset is used to demonstrate the model preprocessing, training and evaluation functionalities in MAIA.\n",
    "- [**CT Lymph Nodes**](https://www.cancerimagingarchive.net/collection/ct-lymph-nodes/) from TCIA: a dataset of 3D lymph node CT scans from The Cancer Imaging Archive. This DICOM dataset is used to demonstrate the data management functionalities in MAIA, including DICOM upload,visualization, annotation and AI model inference (including Active Learning with MONAI Label).\n",
    "\n",
    "The tutorial will cover all the necessary steps to download the Decathlon Spleen dataset, preprocess it, train a [ResEnc nnU-Net](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md) model as a MONAI Bundle, evaluate the model, and finally deploy it for inference on the CT Lymph Nodes dataset. The tutorial will also cover the necessary steps to upload the CT Lymph Nodes dataset, visualize it, annotate it, and perform AI model inference on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59583f0bd43246ad",
   "metadata": {},
   "source": [
    "## Setup environment and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5447525-e0e3-4298-87d8-2efe012d931a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install odict plotly dtale \"monai[nibabel, skimage, scipy, pillow, tensorboard, gdown, ignite, torchvision, itk, tqdm, pandas, mlflow, matplotlib, pydicom]\" \"pydicom==2.4.4\" nnunetv2==2.5.1 fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbf6aeed0a7dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from monai.apps import DecathlonDataset\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "import dtale\n",
    "import dtale.app as dtale_app\n",
    "\n",
    "from monai.bundle import ConfigParser\n",
    "\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c47266462d9e08",
   "metadata": {},
   "source": [
    "## Download the Decathlon Spleen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MONAI_DATA_DIRECTORY\"] = \"/home/maia-user/Documents/GitHub/tutorials/bundle/MONAI/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6902b6e42cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecathlonDataset(root_dir=root_dir,\"Task09_Spleen\",\"training\",download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e7d474b6d8ed0",
   "metadata": {},
   "source": [
    "## Visualize Spleen CT and SEG in 3D Slicer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24e17f-4757-45ab-9d17-0de5a8ca23ad",
   "metadata": {},
   "source": [
    "You can navigate to [Remote Desktop](/user/{USERNAME}/proxy/80/desktop/{USERNAME}) to interact with the Remote Desktop environment and 3D Slicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de310610-a2b6-47d1-a4c3-0d25ce066128",
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer_executable = \"/home/maia-user/Documents/Slicer-5.7.0-2024-08-05-linux-amd64/Slicer\"\n",
    "\n",
    "case_id = \"spleen_2\"\n",
    "\n",
    "ct_volume = Path(root_dir).joinpath(\"Task09_Spleen/imagesTr\",f\"{case_id}.nii.gz\")\n",
    "\n",
    "seg_volume = Path(root_dir).joinpath(\"Task09_Spleen/labelsTr\",f\"{case_id}.nii.gz\")\n",
    "\n",
    "subprocess.run([\n",
    "    slicer_executable,\n",
    "    \"--python-code\", f\"slicer.util.loadVolume('{ct_volume}'); seg=slicer.util.loadSegmentation('{seg_volume}'); seg.CreateClosedSurfaceRepresentation()\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28763d4-f46e-4274-9f0d-ad0314cd39b9",
   "metadata": {},
   "source": [
    "## nnUNet Training\n",
    "\n",
    "To run the nnUNet Training, follow the Tutorial [nnUnet Bundle Training](06_nnunet_monai_bundle.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7642f",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37887f39c3655ad5",
   "metadata": {},
   "source": [
    "To visualize in the 3D Slicer the fold-0 validation predictions, together with the ground truth and the CT volume, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(root_dir).joinpath(\"nnUNet/nnUNet_raw_data_base/Dataset009_Task09_Spleen/datalist.json\")) as f:\n",
    "    datalist = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_0_datalist_cases = [case for case in datalist['training'] if case['fold'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843766b-ae37-4e53-aade-b3d2da5755d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer_executable = \"/home/maia-user/Documents/Slicer-5.7.0-2024-08-05-linux-amd64/Slicer\"\n",
    "\n",
    "case =fold_0_datalist_cases[0]\n",
    "\n",
    "case_id = case['image'].split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "new_name = case[\"new_name\"]\n",
    "\n",
    "\n",
    "ct_volume = Path(root_dir).joinpath(\"Task09_Spleen/imagesTr\",f\"{case_id}.nii.gz\")\n",
    "\n",
    "seg_volume = Path(root_dir).joinpath(\"Task09_Spleen/labelsTr\",f\"{case_id}.nii.gz\")\n",
    "\n",
    "pred_volume = Path(root_dir).joinpath(\"nnUNet/nnUNet_trained_models/Dataset009_Task09_Spleen/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/validation\",new_name+\".nii.gz\")\n",
    "\n",
    "subprocess.run([\n",
    "    slicer_executable,\n",
    "    \"--python-code\", f\"slicer.util.loadVolume('{ct_volume}'); pred=slicer.util.loadSegmentation('{pred_volume}'); seg=slicer.util.loadSegmentation('{seg_volume}'); seg.CreateClosedSurfaceRepresentation()\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c49bb5aaa8f16",
   "metadata": {},
   "source": [
    "### Validation Metrics\n",
    "\n",
    "The validation metrics are stored in a JSON file named `summary.json` in the validation folder. We can load the file and visualize the metrics with [DTale](https://github.com/man-group/dtale) using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2eb82a-331f-4616-bdd9-0030f960cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file = Path(root_dir).joinpath(\"nnUNet/nnUNet_trained_models/Dataset009_Task09_Spleen/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/validation\",\"summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf643ae-bf75-4d18-81c0-e7d6e968d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(summary_file) as f:\n",
    "    summary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85500327",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"label_dict\":{\n",
    "        \"Background\": 0,\n",
    "        \"Spleen\": 1\n",
    "    },\n",
    "    \"label_suffix\": \".nii.gz\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda6346-f6a1-4282-8dc6-ba6f5e56a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "label_to_name = {v: k for k, v in config_dict[\"label_dict\"].items()}\n",
    "\n",
    "for case in summary['metric_per_case']:\n",
    "    for label_id in case['metrics']:\n",
    "        for metric in case['metrics'][label_id]:\n",
    "           \n",
    "            df.append({\n",
    "                \"Case\": Path(case['reference_file']).name[:-len(config_dict[\"label_suffix\"])],\n",
    "                \"Label\": label_to_name[int(label_id)],\n",
    "                \"Metric\": metric,\n",
    "                \"Value\": case['metrics'][label_id][metric]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e77bb2-6f72-4b44-acb3-c10685baf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b24cf-182d-4183-8fb3-bf9dda62b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale_app.JUPYTER_SERVER_PROXY = True\n",
    "\n",
    "d = dtale.show(df,host=\"0.0.0.0\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3f1c1-647e-47a2-ace4-7c5ad8dce784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.core.magic import register_cell_magic\n",
    "import os\n",
    "\n",
    "\n",
    "DTALE_URL = d._main_url\n",
    "@register_cell_magic\n",
    "def markdown(line, cell):\n",
    "    return Markdown(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdefb9b-9359-42e8-aa45-830e41aced6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "\n",
    "[DTale]({DTALE_URL})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e1768177a6b7c",
   "metadata": {},
   "source": [
    "The DTale charts can be recreated and visualized in the notebook using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e7045-c349-40b4-a8be-71fd544a9690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DISCLAIMER: 'df' refers to the data you passed in when calling 'dtale.show'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if isinstance(df, (pd.DatetimeIndex, pd.MultiIndex)):\n",
    "\tdf = df.to_frame(index=False)\n",
    "\n",
    "# remove any pre-existing indices for ease of use in the D-Tale code, but this is not required\n",
    "df = df.reset_index().drop('index', axis=1, errors='ignore')\n",
    "df.columns = [str(c) for c in df.columns]  # update columns to strings in case they are numbers\n",
    "\n",
    "df = df.query(\"\"\"`Metric` == 'Dice'\"\"\")\n",
    "\n",
    "chart_data = pd.concat([\n",
    "\tdf['Case'],\n",
    "\tdf['Value'],\n",
    "], axis=1)\n",
    "chart_data = chart_data.sort_values(['Case'])\n",
    "chart_data = chart_data.rename(columns={'Case': 'x'})\n",
    "chart_data = chart_data.dropna()\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "charts = []\n",
    "charts.append(go.Bar(\n",
    "\tx=chart_data['x'],\n",
    "\ty=chart_data['Value']\n",
    "))\n",
    "figure = go.Figure(data=charts, layout=go.Layout({\n",
    "    'barmode': 'group',\n",
    "    'legend': {'orientation': 'h', 'y': -0.3},\n",
    "    'title': {'text': 'Validation Fold 0, Dice score'},\n",
    "    'xaxis': {'title': {'text': 'Case'}},\n",
    "    'yaxis': {'title': {'text': 'Dice'}, 'type': 'linear'}\n",
    "}))\n",
    "\n",
    "# If you're having trouble viewing your chart in your notebook try passing your 'chart' into this snippet:\n",
    "#\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "#\n",
    "init_notebook_mode(connected=True)\n",
    "for chart in charts:\n",
    "    chart.pop('id', None) # for some reason iplot does not like 'id'\n",
    "#iplot(figure)\n",
    "\n",
    "figure.write_html(\"Fold_0_Val_Dice.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328ca1d-1e92-4b95-8a8b-0c75d8ae76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Metric\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd83c8-edb8-49ae-a9c7-03c231bd3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Metric\"]).describe()['Value']['mean'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c055b67677ddff",
   "metadata": {},
   "source": [
    "Finally, we can upload the validation metrics and the plots to MLFlow using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7a4a7-162b-4a47-b1cf-e51b9101b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "mlflow.set_experiment(\"Task09_Spleen\")\n",
    "\n",
    "with mlflow.start_run(run_id=\"1b31a872e1b644cb9787cf91b60be449\"):\n",
    "    mean_dice = df.groupby([\"Metric\"]).describe()['Value']['mean'].values[0]\n",
    "    \n",
    "    mlflow.log_metric(\"Val_Dice_Fold_0\", mean_dice)\n",
    "    mlflow.log_artifact(\"Fold_0_Val_Dice.html\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdba2c483d1906f",
   "metadata": {},
   "source": [
    "In the final step of the validation phase, we export the trained model, saving the nnUNet Bundle as a zip file (`Task09_Spleen_nnUNet.zip`). The zip file contains the model, the configuration files, and the environment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c9cfa-8eba-46d5-bb48-8c82e793f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export nnUNet_raw=\"/home/maia-user/Documents/GitHub/tutorials/bundle/MONAI/Data/nnUNet/nnUNet_raw_data_base\"\n",
    "export nnUNet_preprocessed=\"/home/maia-user/Documents/GitHub/tutorials/bundle/MONAI/Data/nnUNet/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/maia-user/Documents/GitHub/tutorials/bundle/MONAI/Data/nnUNet/nnUNet_trained_models\"\n",
    "\n",
    "touch /home/maia-user/Documents/GitHub/tutorials/bundle/MONAI/Data/nnUNet/nnUNet_trained_models/Dataset009_Task09_Spleen/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/progress.png\n",
    "\n",
    "nnUNetv2_export_model_to_zip -d 009 -c 3d_fullres -f 0 -o Task09_Spleen_nnUNet.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610c3f7b3b01f30",
   "metadata": {},
   "source": [
    "## Package MONAI Bundle\n",
    "\n",
    "After completing the training and validation of the nnUNet model, we can package the model as a MONAI Bundle, to be used for inference (i.e. Active Learning with MONAI Label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4828ab-9650-4c36-b797-ac6d94b30feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export BUNDLE_ROOT=nnUNetBundle\n",
    "export PYTHONPATH=$PYTHONPATH:$BUNDLE_ROOT\n",
    "\n",
    "python -m monai.bundle run \\\n",
    "    --config-file $BUNDLE_ROOT/configs/inference.yaml \\\n",
    "    --bundle-root $BUNDLE_ROOT \\\n",
    "    --data-dir $BUNDLE_ROOT/test_input \\\n",
    "    --output-dir $BUNDLE_ROOT/test_output \\\n",
    "    --logging-file $BUNDLE_ROOT/configs/logging.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218be4f305153db",
   "metadata": {},
   "source": [
    "To visualize the prediction in 3D Slicer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a5db0-1d8b-4130-a4a5-3e947b342da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "slicer_executable = \"/home/maia-user/Documents/Slicer-5.7.0-2024-08-05-linux-amd64/Slicer\"\n",
    "\n",
    "bundle_root = \"/home/maia-user/Documents/GitHub/tutorials/bundle/nnUNetBundle\"\n",
    "data_dir = os.path.join(bundle_root, \"test_input\")\n",
    "ct_volume = os.path.join(data_dir, \"spleen_1\",\"spleen_1.nii.gz\")\n",
    "\n",
    "pred_volume = os.path.join(bundle_root, \"test_output\", \"spleen_1\", \"spleen_1_prediction.nii.gz\")\n",
    "\n",
    "subprocess.run([\n",
    "    slicer_executable,\n",
    "    \"--python-code\", f\"slicer.util.loadVolume('{ct_volume}'); pred=slicer.util.loadSegmentation('{pred_volume}'); pred.CreateClosedSurfaceRepresentation()\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f21258d74bfa7",
   "metadata": {},
   "source": [
    "We finally export the python environment and the requirements for the MONAI Bundle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844b1f8-7960-4cf9-97e3-884db90e18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "conda env export -n MONAI > nnUNetBundle/environment.yml\n",
    "python -m pip freeze > nnUNetBundle/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b38cca-e5c1-4f56-bd44-e03097653e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "zip -r Task09_Spleen_Bundle.zip nnUNetBundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d360d4-124e-43de-9eee-bb353374ae68",
   "metadata": {},
   "source": [
    "## MLFlow Model Upload\n",
    "\n",
    "To store the model and be able to deploy it for inference in future use cases, we can upload it to MLFlow. We will use the MLFlow Python API to log the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18898f8-eff4-4916-9b96-d52cf2170951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "from monai.bundle import ConfigParser\n",
    "import torch\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "sys.path.append(\"nnUNetBundle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe37c42-7ae8-4233-a049-a28b63ae7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_files = [f.path for f in os.scandir(\"nnUNetBundle/configs\") if f.path.endswith(\"inference.yaml\")]\n",
    "\n",
    "config = {}\n",
    "for config_file in config_files:\n",
    "    with open(config_file, 'r') as file:\n",
    "        config.update(yaml.safe_load(file))\n",
    "\n",
    "config[\"bundle_root\"] = \"nnUNetBundle\"\n",
    "\n",
    "parser = ConfigParser(config,globals={\"os\": \"os\",\n",
    "                                      \"pathlib\":\"pathlib\",\n",
    "                                      \"json\":\"json\",\n",
    "                                      \"ignite\":\"ignite\"\n",
    "                                     })\n",
    "\n",
    "parser.parse(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954a3d2-1023-4434-bf7e-8ac778c158b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = parser.get_parsed_content(\"network_def\",instantiate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d65dd-d938-4594-9a7b-80ae986f585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.network_weights.load_state_dict(torch.load(\"nnUNetBundle/models/model.pt\")['network_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca526ca8-6cf2-41a6-ad9f-15a2e77f55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://127.0.0.1:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed432d0a-9684-4b6e-bc0a-ab1f72cf95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"nnUNet_Bundle_Spleen\")\n",
    "mlflow.end_run()\n",
    "\n",
    "\n",
    "\n",
    "input_schema = Schema(\n",
    "    [\n",
    "        TensorSpec(np.dtype(np.float32), (1, *net.predictor.configuration_manager.patch_size),name=\"ct\")\n",
    "         \n",
    "    ]\n",
    "    \n",
    ")\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.float32), (1, *net.predictor.configuration_manager.patch_size),name=\"Spleen\")])\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "with mlflow.start_run(run_id='01bd0abe19744cc598acb9a56c2e4ae5'):\n",
    "    mlflow.pytorch.log_model(\n",
    "        net,\n",
    "        \"Task09_Spleen\",\n",
    "        signature=signature,\n",
    "        conda_env = \"/home/maia-user/Documents/GitHub/tutorials/bundle/nnUNetBundle/environment.yml\",\n",
    "        registered_model_name = \"Task09_Spleen\",\n",
    "        extra_files = [\n",
    "            \"/home/maia-user/Documents/GitHub/tutorials/bundle/Task09_Spleen_Bundle.zip\",\n",
    "            \"/home/maia-user/Documents/GitHub/tutorials/bundle/nnUNetBundle/environment.yml\",\n",
    "            \"/home/maia-user/Documents/GitHub/tutorials/bundle/nnUNetBundle/requirements.txt\"\n",
    "        ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MONAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
